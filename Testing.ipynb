{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/healthy-ml/scratch/abinitha/miniconda3/envs/contrastive/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from tree import Tree\n",
    "from data import load_data\n",
    "\n",
    "class_tree = None\n",
    "distance_matrix = None\n",
    "\n",
    "# use 'conda install pytorch torchvision -c pytorch' in python env to import; if using Colab probably use pip \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "def precompute_lca_distances(labels, class_tree):\n",
    "    num_labels = len(labels)\n",
    "    lca_matrix = torch.zeros((num_labels, num_labels), dtype=torch.long, device='cuda')\n",
    "    distance_matrix = torch.zeros((num_labels, num_labels), dtype=torch.float, device='cuda')\n",
    "\n",
    "    # Precompute LCAs and distances\n",
    "    for i in range(num_labels):\n",
    "        for j in range(i + 1, num_labels):\n",
    "            lca = class_tree.find_lca(labels[i].item(), labels[j].item())\n",
    "            distance_i = class_tree.find_distance_to_ancestor(labels[i].item(), lca)\n",
    "            distance_j = class_tree.find_distance_to_ancestor(labels[j].item(), lca)\n",
    "            min_distance = min(distance_i, distance_j)\n",
    "            lca_matrix[i, j] = lca\n",
    "            lca_matrix[j, i] = lca\n",
    "            distance_matrix[i, j] = min_distance\n",
    "            distance_matrix[j, i] = min_distance\n",
    "\n",
    "    return distance_matrix\n",
    "\n",
    "# Basic Contrastive Learning Model\n",
    "class ContrastiveModel(nn.Module):\n",
    "    def __init__(self, num_classes, embedding_dim=128):\n",
    "        super(ContrastiveModel, self).__init__()\n",
    "        # Using ResNet backbone since we are using ImageNet and therefore compatible, feel free to change\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        \n",
    "        num_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        \n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(num_features, embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embedding_dim, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)  # Extract features\n",
    "        embeddings = self.projection_head(features)  # Project embeddings\n",
    "        logits = self.classifier(embeddings)  # Classification logits\n",
    "        return embeddings, logits\n",
    "\n",
    "\n",
    "# Define the NCE Loss\n",
    "class NCELoss(nn.Module):\n",
    "    def __init__(self, temperature=0.07, dist_func_param=1):\n",
    "        super(NCELoss, self).__init__()\n",
    "        self.temperature = temperature\n",
    "        self.dist_func_param = dist_func_param\n",
    "\n",
    "    def forward(self, embeddings, labels):\n",
    "        global distance_matrix\n",
    "        # Normalize embeddings to unit vectors\n",
    "        embeddings = nn.functional.normalize(embeddings, dim=1)\n",
    "\n",
    "        similarity_matrix = torch.matmul(embeddings, embeddings.T) / self.temperature\n",
    "\n",
    "        # Mask out self-similarity\n",
    "        mask = torch.eye(similarity_matrix.size(0), device=similarity_matrix.device).bool()\n",
    "        similarity_matrix = similarity_matrix.masked_fill(mask, float('-inf'))\n",
    "\n",
    "        # Create targets: positive samples have the same label\n",
    "        labels = labels.unsqueeze(0) == labels.unsqueeze(1)\n",
    "        #positives = labels.float()\n",
    "        distances = torch.exp(-self.dist_func_param * distance_matrix[labels][:, labels])\n",
    "\n",
    "        # Compute log-softmax and NCE loss\n",
    "        log_prob = nn.functional.log_softmax(similarity_matrix, dim=1)\n",
    "        #loss = -torch.sum(log_prob * positives) / labels.sum() #loss is only how far apart the positives are\n",
    "        loss = -torch.sum(log_prob * distances) / labels.sum() #loss is only how far apart the positives are\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/healthy-ml/scratch/abinitha/miniconda3/envs/contrastive/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/data/healthy-ml/scratch/abinitha/miniconda3/envs/contrastive/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/tmp/ipykernel_1989107/2889889292.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  distance_matrix = torch.tensor(precompute_lca_distances(np.array(contrastive_classes), class_tree), device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1.], device='cuda:0')\n",
      "LABELS: \n",
      "tensor([219, 192, 191, 198, 215, 165, 188, 196, 211, 210, 171, 192, 206, 168,\n",
      "        197, 168, 165, 167, 210, 191, 191, 164, 216, 208, 189, 197, 172, 176,\n",
      "        173, 163])\n",
      "CONTRASTIVE LABELS: \n",
      "tensor([ 2,  7,  7,  7,  2, 12,  7,  7,  2,  2, 12,  7,  2, 12,  7, 12, 12, 12,\n",
      "         2,  7,  7, 12,  2,  2,  7,  7, 12, 12, 12, 12], device='cuda:0')\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m embeddings, logits \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m nce_loss \u001b[38;5;241m=\u001b[39m nce_loss_fn(embeddings, contr_labels)\n\u001b[1;32m     48\u001b[0m classification_loss \u001b[38;5;241m=\u001b[39m classification_loss_fn(logits, labels)\n\u001b[1;32m     49\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m nce_loss \u001b[38;5;241m+\u001b[39m classification_loss  \u001b[38;5;66;03m# Combined loss\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/contrastive/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/contrastive/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[1], line 83\u001b[0m, in \u001b[0;36mNCELoss.forward\u001b[0;34m(self, embeddings, labels)\u001b[0m\n\u001b[1;32m     81\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m labels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#positives = labels.float()\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m distances \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdist_func_param \u001b[38;5;241m*\u001b[39m distance_matrix[labels][:, labels])\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# Compute log-softmax and NCE loss\u001b[39;00m\n\u001b[1;32m     86\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mlog_softmax(similarity_matrix, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataloader, val_dataloader, dogs, num_total_classes = load_data()\n",
    "class_tree = Tree(dogs)\n",
    "\n",
    "contrastive_classes_specificity = 2\n",
    "contrastive_classes = class_tree.nodes_at_depth(contrastive_classes_specificity)\n",
    "contrastive_class_to_id = {_cls: i for i, _cls in enumerate(contrastive_classes)}\n",
    "\n",
    "clf_classes_specificity = 1\n",
    "clf_classes = class_tree.nodes_at_depth(clf_classes_specificity)\n",
    "clf_class_to_id = {_cls: i for i, _cls in enumerate(clf_classes)}\n",
    "\n",
    "num_classes = len(clf_classes)\n",
    "\n",
    "model = ContrastiveModel(num_classes).to(device=device)\n",
    "nce_loss_fn = NCELoss().cuda() # Generally probably add all of this to Colab to use the GPU \n",
    "classification_loss_fn = nn.CrossEntropyLoss().to(device=device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Precompute distance matrix\n",
    "distance_matrix = torch.tensor(precompute_lca_distances(np.array(contrastive_classes), class_tree), device=device)\n",
    "print(distance_matrix[2][:2])\n",
    "\n",
    "# Training loop\n",
    "# TODO: add in evals or call to eval.py file perhaps? \n",
    "for epoch in range(2):  # Using two epochs to test but add more epochs\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        images, labels = batch\n",
    "        print(\"LABELS: \")\n",
    "        print (labels)\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "\n",
    "        # for each image, find the label at the correct classification level\n",
    "        contr_labels = torch.tensor([class_tree.which_ancestor(label.item(), clf_classes) for label in labels], device='cuda')\n",
    "        print(\"CONTRASTIVE LABELS: \")\n",
    "        print(contr_labels)\n",
    "\n",
    "        # Map labels to their IDs\n",
    "        class_labels = torch.tensor([clf_class_to_id[contr_label.item()] for contr_label in contr_labels], device='cuda')\n",
    "\n",
    "        # Forward pass\n",
    "        embeddings, logits = model(images)\n",
    "        \n",
    "        # Compute losses\n",
    "        nce_loss = nce_loss_fn(embeddings, contr_labels)\n",
    "        classification_loss = classification_loss_fn(logits, labels)\n",
    "        total_loss = nce_loss + classification_loss  # Combined loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/2], Loss: {running_loss/len(train_dataloader):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
